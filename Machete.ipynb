{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndresMontesDeOca/RegresionAvanzada/blob/main/Machete.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eda0864a",
      "metadata": {
        "id": "eda0864a"
      },
      "source": [
        "# MACHETE"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Logbook"
      ],
      "metadata": {
        "id": "ZrfIpM4oo-bq"
      },
      "id": "ZrfIpM4oo-bq"
    },
    {
      "cell_type": "code",
      "source": [
        "# Autor: Andres Montes de Oca\n",
        "\n",
        "# 31/05/23 -> Creacion de la Notebook\n",
        "# 31/05/23 -> Tests Normalidad, Homocedasticidad Residuos\n",
        "# 06/06/23 -> Test No-autoorrelacion de Residuos\n",
        "# 17/06/23 -> Transfomraciones Box Clox\n",
        "# 19/06/23 -> Migrated to Google Colab\n",
        "# 20/06/23 -> R Magic\n",
        "# 22/06/23 -> Deteccion Outliers e Influyentes"
      ],
      "metadata": {
        "id": "HO1BXrWJo83M"
      },
      "id": "HO1BXrWJo83M",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "bbf8c17a",
      "metadata": {
        "id": "bbf8c17a",
        "outputId": "36b31d53-7808-4f83-f1f8-81b641fa6cfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pingouin\n",
            "  Downloading pingouin-0.5.3-py3-none-any.whl (198 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/198.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.6/198.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.10/dist-packages (from pingouin) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from pingouin) (1.10.1)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/dist-packages (from pingouin) (1.5.3)\n",
            "Requirement already satisfied: matplotlib>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from pingouin) (3.7.1)\n",
            "Requirement already satisfied: seaborn>=0.11 in /usr/local/lib/python3.10/dist-packages (from pingouin) (0.12.2)\n",
            "Requirement already satisfied: statsmodels>=0.13 in /usr/local/lib/python3.10/dist-packages (from pingouin) (0.13.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pingouin) (1.2.2)\n",
            "Collecting pandas-flavor>=0.2.0 (from pingouin)\n",
            "  Downloading pandas_flavor-0.5.0-py3-none-any.whl (7.1 kB)\n",
            "Collecting outdated (from pingouin)\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from pingouin) (0.8.10)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->pingouin) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->pingouin) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->pingouin) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->pingouin) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->pingouin) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->pingouin) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->pingouin) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->pingouin) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->pingouin) (2022.7.1)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.10/dist-packages (from pandas-flavor>=0.2.0->pingouin) (2022.12.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from pandas-flavor>=0.2.0->pingouin) (0.2)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.13->pingouin) (0.5.3)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated->pingouin) (67.7.2)\n",
            "Collecting littleutils (from outdated->pingouin)\n",
            "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from outdated->pingouin) (2.27.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pingouin) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pingouin) (3.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.2->statsmodels>=0.13->pingouin) (1.16.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->outdated->pingouin) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->outdated->pingouin) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->outdated->pingouin) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->outdated->pingouin) (3.4)\n",
            "Building wheels for collected packages: littleutils\n",
            "  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7029 sha256=3ab7f9e9aa73166997146a4903183c80efe1be00e6562d6650650cad91c42fc4\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/fe/b0/27a9892da57472e538c7452a721a9cf463cc03cf7379889266\n",
            "Successfully built littleutils\n",
            "Installing collected packages: littleutils, outdated, pandas-flavor, pingouin\n",
            "Successfully installed littleutils-0.2.2 outdated-0.2.2 pandas-flavor-0.5.0 pingouin-0.5.3\n",
            "Collecting rpy2==3.5.1\n",
            "  Downloading rpy2-3.5.1.tar.gz (201 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.7/201.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from rpy2==3.5.1) (1.15.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from rpy2==3.5.1) (3.1.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from rpy2==3.5.1) (2022.7.1)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from rpy2==3.5.1) (5.0.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.10.0->rpy2==3.5.1) (2.21)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->rpy2==3.5.1) (2.1.3)\n",
            "Building wheels for collected packages: rpy2\n",
            "  Building wheel for rpy2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rpy2: filename=rpy2-3.5.1-cp310-cp310-linux_x86_64.whl size=318086 sha256=d186b1536267f549802a360371598e758531537432fe450495800dca4c66a193\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/a6/ff/4e75dd1ce1cfa2b9a670cbccf6a1e41c553199e9b25f05d953\n",
            "Successfully built rpy2\n",
            "Installing collected packages: rpy2\n",
            "  Attempting uninstall: rpy2\n",
            "    Found existing installation: rpy2 3.5.5\n",
            "    Uninstalling rpy2-3.5.5:\n",
            "      Successfully uninstalled rpy2-3.5.5\n",
            "Successfully installed rpy2-3.5.1\n"
          ]
        }
      ],
      "source": [
        "# Instalacion de Paquetes\n",
        "!pip install pingouin # No incluido en Google Colab\n",
        "# !pip install scipy\n",
        "# !pip install statsmodels\n",
        "\n",
        "# Version rpy2 que no tiene problemas de compatibilidad\n",
        "!pip install rpy2==3.5.1\n",
        "\n",
        "# Cargamos Librerias y Datos\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pingouin as pg\n",
        "from scipy import stats as st\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "import statsmodels.tools.tools as smt\n",
        "import math\n",
        "\n",
        "# Ignorar Warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Asthetics\n",
        "sns.set(style='ticks', context='notebook', palette='colorblind', font_scale=1, color_codes=True)\n",
        "\n",
        "# Recursion limit errors with R Magic\n",
        "import sys\n",
        "# sys.setrecursionlimit(50000)\n",
        "\n",
        "# Activamos R magic\n",
        "%load_ext rpy2.ipython"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf6ec746",
      "metadata": {
        "id": "bf6ec746"
      },
      "source": [
        "### Libreria rpy2 (Python <==> R)\n",
        "- Usamos R Magic, asi que no las necesitamos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "436c2819",
      "metadata": {
        "id": "436c2819"
      },
      "outputs": [],
      "source": [
        "# # Import rpy2 for dataframe conversion\n",
        "# import rpy2.robjects as ro\n",
        "# from rpy2.robjects.packages import importr\n",
        "# from rpy2.robjects import pandas2ri\n",
        "# from rpy2.robjects.conversion import localconverter\n",
        "# from rpy2.robjects import globalenv\n",
        "\n",
        "# ###### Pandas DataFrames and Series conversion ########\n",
        "# # Cargamos un DataSet cualquira en Python, para que no de error\n",
        "# data_P = sns.load_dataset('iris')\n",
        "# Serie = data_P['petal_length']\n",
        "\n",
        "# # Convert the Python DataFrame to the R dataframe\n",
        "# %R -i data_P\n",
        "\n",
        "# with localconverter(ro.default_converter + pandas2ri.converter):\n",
        "#   data_R = ro.conversion.py2rpy(data_P)\n",
        "# # Create a variable name in R's Global Environment\n",
        "# globalenv['data_R'] = data_R\n",
        "\n",
        "# # Convert Python Series to R vectors\n",
        "# vec_float_R = ro.vectors.FloatVector(Serie)\n",
        "# # vec_int_R = ro.vectors.IntVector(Serie)\n",
        "# # vec_str_R = ro.vectors.StrVector(Serie)\n",
        "# globalenv['vec_float_R'] = vec_float_R\n",
        "\n",
        "# # Convert R datadrame/vector to Python DataFrame/Vector\n",
        "# %R -o data_R\n",
        "\n",
        "# with localconverter(ro.default_converter + pandas2ri.converter):\n",
        "#   data_P = ro.conversion.rpy2py(data_R)\n",
        "\n",
        "# # Importar R-Functions a Python como Objetos(sin uso)\n",
        "# shapiro_test = ro.r('shapiro.test')\n",
        "# result = shapiro_test(vec_float_R)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Instalaciones Individuales en Bash"
      ],
      "metadata": {
        "id": "KfM50m-wCz4b"
      },
      "id": "KfM50m-wCz4b"
    },
    {
      "cell_type": "code",
      "source": [
        "# system(sudo apt install libgsl-dev) # -> Rapido"
      ],
      "metadata": {
        "id": "pZI0hXx4DbdA"
      },
      "execution_count": 4,
      "outputs": [],
      "id": "pZI0hXx4DbdA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Instalacion de Librerias para R en Google Colab"
      ],
      "metadata": {
        "id": "RWsE_ORpdjnL"
      },
      "id": "RWsE_ORpdjnL"
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "\n",
        "# ## MVN Henze-Zirkler Test ### -> Lento\n",
        "# # system(sudo apt install libgsl-dev)\n",
        "# install.packages('MVN')\n",
        "\n",
        "# ## QQ Plot, Bonferroni, outlierTest ### -> Lento\n",
        "# install.packages('car')\n",
        "\n",
        "## Wald Test ### -> Rapido\n",
        "install.packages('aod')\n",
        "\n",
        "# LRM Tests ### -> Rapido\n",
        "install.packages('lmtest')\n",
        "\n",
        "## Box-Cox Transformation ### -> Rapido\n",
        "install.packages('MASS')\n",
        "\n",
        "## Estimaciones Robustas ### ->\n",
        "# install.packages('robustbase')\n",
        "# install.packages('olsrr')\n",
        "# install.packages('quantreg')\n",
        "\n",
        "## Seleccion de Variables ### -> Rapido\n",
        "install.packages('leaps') # -> regsubsets"
      ],
      "metadata": {
        "id": "8ufTcCWTEAvQ"
      },
      "id": "8ufTcCWTEAvQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b00fc712",
      "metadata": {
        "id": "b00fc712"
      },
      "source": [
        "## Cargas de Datasets from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "74cd8b72",
      "metadata": {
        "id": "74cd8b72"
      },
      "outputs": [],
      "source": [
        "# Code to read csv file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "################################# Datasets ###################################\n",
        "# Grasa de Cerdos\n",
        "id = '153lGVzdixcHT-keKg8qmvaoWdPHg6_tB'\n",
        "downloaded = drive.CreateFile({'id':id})\n",
        "downloaded.GetContentFile('grasacerdos.xlsx')\n",
        "dataG = pd.read_excel('grasacerdos.xlsx', index_col='Obs') # Cargamos el Dataset\n",
        "dataG = dataG.replace(to_replace=',', value='.', regex=True) # Reemplazo , por .\n",
        "dataG = dataG.astype('float') # Transformo en float\n",
        "%R -i dataG\n",
        "\n",
        "######################################################\n",
        "# Peso, Edad, Colesterol\n",
        "id = '17Dv1WcWlc9ojWa6bnSfD7TCRaVKCKqj0'\n",
        "downloaded = drive.CreateFile({'id':id})\n",
        "downloaded.GetContentFile('peso_edad_colest.xlsx')\n",
        "dataP = pd.read_excel('peso_edad_colest.xlsx')\n",
        "%R -i dataP\n",
        "\n",
        "# # Convert the Python DataFrame to the R dataframe\n",
        "# with localconverter(ro.default_converter + pandas2ri.converter):\n",
        "#   dataP_R = ro.conversion.py2rpy(dataP)\n",
        "# # Create a variable name in R's Global Environment\n",
        "# globalenv['dataP_R'] = dataP_R\n",
        "\n",
        "######################################################\n",
        "# Cars con Modelo Lineal\n",
        "id = '15pf-6P4Ek2rp6mYmfOybHRqAxqOoTp6i'\n",
        "downloaded = drive.CreateFile({'id':id})\n",
        "downloaded.GetContentFile('cars.csv')\n",
        "dataC = pd.read_csv('cars.csv')\n",
        "model_cars = smf.ols('dist ~ speed', data=dataC).fit()\n",
        "%R -i dataC\n",
        "\n",
        "######################################################\n",
        "# University\n",
        "id = '16kLQNXhyweAi38xR2IeQCCagVcU725UZ'\n",
        "downloaded = drive.CreateFile({'id':id})\n",
        "downloaded.GetContentFile('University.csv')\n",
        "dataU = pd.read_csv('University.csv')\n",
        "%R -i dataU\n",
        "\n",
        "######################################################\n",
        "# Iris(Python)\n",
        "dataI = sns.load_dataset('iris')\n",
        "\n",
        "# # Iris(R) -> DataFrame to dataframe\n",
        "# with localconverter(ro.default_converter + pandas2ri.converter):\n",
        "#   dataI_R = ro.conversion.py2rpy(dataI.drop(columns='species'))\n",
        "# # Create a variable name in R's global environment\n",
        "# globalenv['dataI_R'] = dataI_R\n",
        "\n",
        "# # Serie to Vector\n",
        "# x_R = ro.FloatVector(dataI['petal_length'])\n",
        "# w_R = ro.FloatVector(dataI['petal_width'])\n",
        "# globalenv['x_R'] = x_R\n",
        "# globalenv['w_R'] = w_R\n",
        "%R -i dataI\n",
        "\n",
        "######################################################\n",
        "# Energia\n",
        "id = '15R-MejMHi1D0y0JUEGxyC3-fsjpYHEUv'\n",
        "downloaded = drive.CreateFile({'id':id})\n",
        "downloaded.GetContentFile('energia.xlsx')\n",
        "dataE = pd.read_excel('energia.xlsx')\n",
        "dataE.rename(columns={'Energía':'Energia'}, inplace=True)\n",
        "%R -i dataE\n",
        "\n",
        "######################################################\n",
        "# Inmobiliara\n",
        "id = '17HWmCOH02KnzViqTkIWf9RGAkgzGllMP'\n",
        "downloaded = drive.CreateFile({'id':id})\n",
        "downloaded.GetContentFile('inmobiliaria.csv')\n",
        "dataN = pd.read_csv('inmobiliaria.csv', sep=';')\n",
        "%R -i dataN\n",
        "\n",
        "######################################################\n",
        "# Estudio\n",
        "id = '15Mu2BfCRXCxImCCusMA8hoCynxAKbilK'\n",
        "downloaded = drive.CreateFile({'id':id})\n",
        "downloaded.GetContentFile('estudio.csv')\n",
        "dataT = pd.read_csv('estudio.csv', sep=';')\n",
        "%R -i dataT\n",
        "\n",
        "######################################################\n",
        "# Gorriones (Dataset Principal para MACHETE)\n",
        "id = '15G6jIOMiuWaTs-qy7eUXwhED4delBMl6'\n",
        "downloaded = drive.CreateFile({'id':id})\n",
        "downloaded.GetContentFile('gorriones.xlsx')\n",
        "dataO = pd.read_excel('gorriones.xlsx')\n",
        "dataO.rename(columns=\n",
        "            {'largototal':'Largo', 'extension ':'Alas', 'cabeza':'Cabeza',\n",
        "             'humero':'Pata', 'esternon':'Cuerpo', 'sobrevida ':'Target'},\n",
        "            inplace=True)\n",
        "dataO.drop(columns=['pajaro', 'Target'], inplace=True)\n",
        "%R -i dataO\n",
        "# Gorriones (Dataset Principal para MACHETE)\n",
        "data = dataO\n",
        "%R -i data\n",
        "\n",
        "######################################################\n",
        "# Duncan\n",
        "id = '17aCADG_APoFTsCdPvdI5T25gBAUE8U2T'\n",
        "downloaded = drive.CreateFile({'id':id})\n",
        "downloaded.GetContentFile('Duncan.csv')\n",
        "dataD = pd.read_csv('Duncan.csv')\n",
        "%R -i dataD\n",
        "\n",
        "######################################################\n",
        "# Carseats\n",
        "id = '17d0yuvZLyRBM5INORFMzlJSBzkL-I8wI'\n",
        "downloaded = drive.CreateFile({'id':id})\n",
        "downloaded.GetContentFile('Carseats.csv')\n",
        "dataS = pd.read_csv('Carseats.csv')\n",
        "%R -i dataS"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analisis de Variables"
      ],
      "metadata": {
        "id": "Bj2eFW6ZFMUD"
      },
      "id": "Bj2eFW6ZFMUD"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "cf05b562",
      "metadata": {
        "id": "cf05b562"
      },
      "outputs": [],
      "source": [
        "# # Relacion Lineal Grafica\n",
        "# sns.scatterplot(data=data, x='Largo', y='Alas')\n",
        "# plt.show()\n",
        "\n",
        "# # Multicollonearity - Eeach independent variable should be independent from other independent variables\n",
        "# print(pg.corr(data['Largo'], data['Alas'], method='pearson')) # Entre dos varibales, H0 -> Variables Independientes\n",
        "# print(pg.corr(data['Largo'], data['Alas'], method='spearman')) # Cuando no se cumplen los supuestos de Pearson\n",
        "# # %R cor.test(data$Largo, data$Alas, method='pearson')\n",
        "# display(sns.heatmap(data.corr(), vmin=-1, vmax=1, cmap='RdYlGn', annot=True)) # Todos contra todos\n",
        "\n",
        "# # Analsis de Noramlidad Multi-Variariable (Henze-Zirkler) -> Python\n",
        "# print(pg.multivariate_normality(data.drop(columns='Largo'))) # Henze-Zirkler Test, H0 -> Multiv Normal Dist\n",
        "\n",
        "# # Analsis de Noramlidad Multi-Variariable (Henze-Zirkler) -> R\n",
        "# # library(MVN)\n",
        "# # mvn_result <- mvn(data, mvnTest = 'hz')\n",
        "# # print(mvn_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression Models"
      ],
      "metadata": {
        "id": "aqpTI97ucr0F"
      },
      "id": "aqpTI97ucr0F"
    },
    {
      "cell_type": "code",
      "source": [
        "# # Linear Regression\n",
        "# %%R\n",
        "\n",
        "# model <- lm('Largo ~ Alas + Cabeza + Pata + Cuerpo', data=data)\n",
        "# resid <- model$resid\n",
        "# fitted <- model$fitted.values\n",
        "\n",
        "# print(summary(model))\n",
        "# print(anova(model))\n",
        "\n",
        "# # Bandas de Prediccion\n",
        "# predichos <- predict(object=model, interval='prediction', level=0.95) # newdata = newdata\n",
        "# nuevos_datos <- data.frame(predichos, data)\n",
        "# print(head(predichos))\n",
        "# print(head(nuevos_datos))\n",
        "# print(confint(model))\n",
        "\n",
        "# # Datos a Predecir (Python, other example)\n",
        "# # to_predict = [25, 48]\n",
        "# # newdata = pd.Series(to_predict, name='edad').to_frame()"
      ],
      "metadata": {
        "id": "H4kJn7W3Fas6"
      },
      "id": "H4kJn7W3Fas6",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Graficamos en Python\n",
        "# %R -o nuevos_datos\n",
        "\n",
        "# # Grafico\n",
        "# sns.regplot(data=nuevos_datos, x='Alas', y='Largo')\n",
        "# sns.lineplot(data=nuevos_datos, x='Alas', y='lwr', linestyle='--', color='r', ci=None)\n",
        "# sns.lineplot(data=nuevos_datos, x='Alas', y='upr', linestyle='--', color='r', ci=None)\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "0eh_UlkkFhXL"
      },
      "id": "0eh_UlkkFhXL",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # LRM en Python\n",
        "\n",
        "# # Generamos el Modelo\n",
        "# data = sm.add_constant(data)\n",
        "# model = smf.ols('Largo ~ Alas + Cabeza + Pata + Cuerpo', data=data).fit()\n",
        "# print(model.summary())"
      ],
      "metadata": {
        "id": "BRe7V4KrcsGT"
      },
      "id": "BRe7V4KrcsGT",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Wald Test (revisar)\n",
        "Mide si la Variable X es lo suficientemente significativa como para explicar la"
      ],
      "metadata": {
        "id": "Vn93BkqUKkOb"
      },
      "id": "Vn93BkqUKkOb"
    },
    {
      "cell_type": "code",
      "source": [
        "# %%R\n",
        "\n",
        "# library(aod)\n",
        "\n",
        "# # Wald Test para indentificar variables significativas\n",
        "# wald.test(Sigma = vcov(model), b = coef(model), Terms = 3) # Cuerpo| H0: Coef = 0 (Var no significativa)\n"
      ],
      "metadata": {
        "id": "u2u1biCGKpGn"
      },
      "id": "u2u1biCGKpGn",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analisis de Diagnostico"
      ],
      "metadata": {
        "id": "UF-d2Q40JuGM"
      },
      "id": "UF-d2Q40JuGM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Residuals Nomrality"
      ],
      "metadata": {
        "id": "6PS87hllKYD-"
      },
      "id": "6PS87hllKYD-"
    },
    {
      "cell_type": "code",
      "source": [
        "# %%R\n",
        "\n",
        "# # Analisis de Normalidad en los Residuos\n",
        "# library(car)\n",
        "# qqPlot(resid) # Observaciones que romperian con el supuesto de Normalidad\n",
        "# print(shapiro.test(resid))"
      ],
      "metadata": {
        "id": "eSLP7Yw4KWnH"
      },
      "id": "eSLP7Yw4KWnH",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Python\n",
        "\n",
        "# # Tests Analiticos\n",
        "# display(pg.normality(data['Alas'])) # Shapiro Test(single Var), H0 -> Normal Dist\n",
        "# print(st.anderson(data['Alas'], dist='norm')) # Anderson-Darling SciPy\n",
        "# print(st.kstest(data['Alas'], 'norm'))# Kolmogorov-Smirnov SciPy\n",
        "\n",
        "# # Tests Graficos\n",
        "# pg.qqplot(data['Alas'])\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "GHx3kYbQH16s"
      },
      "id": "GHx3kYbQH16s",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "6a56b196",
      "metadata": {
        "id": "6a56b196"
      },
      "source": [
        "### Residuals Variance (Homosedasticity)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Analisis Analitico (Breusch-Pagan Test) -> R | H0: Residuos Homocedasticos\n",
        "# %%R\n",
        "\n",
        "# library(lmtest)\n",
        "# bptest(model)"
      ],
      "metadata": {
        "id": "aM8aPx10LXlm"
      },
      "id": "aM8aPx10LXlm",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "94129b70",
      "metadata": {
        "id": "94129b70"
      },
      "outputs": [],
      "source": [
        "# # # Analsis Grafico -> Python\n",
        "\n",
        "# # Importamos desde R\n",
        "# %R -o resid\n",
        "# %R -o fitted\n",
        "\n",
        "# plt.scatter(x=fitted, y=resid)\n",
        "# plt.xlabel( 'Prediccion')\n",
        "# plt.ylabel('Residuo')\n",
        "# plt.title('Distribucion de Residuos')\n",
        "# plt.axhline(color='grey', linestyle='dashed', alpha=0.5)\n",
        "# plt.show()\n",
        "# # No se observa estructura de embudo\n",
        "\n",
        "# # # Analisis Analitico Python\n",
        "# # BP, p_value, _, _ =sm.stats.het_breuschpagan(model.resid, model.model.exog)\n",
        "# # print('Estadistico BP y p-value:', BP, p_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd5bc19b",
      "metadata": {
        "id": "cd5bc19b"
      },
      "source": [
        "### Residuals Auto-Correlation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Analisis Analitico (Durbin-Watson Test) -> R | H0 No Auto-Correlacion\n",
        "# # 2=No Correlacion (Independecia)| 0=Correlacion Pos | 4=Correlacion Neg\n",
        "# %%R\n",
        "\n",
        "# library(lmtest)\n",
        "# dwtest(model, alternative='two.sided', iterations=1000)"
      ],
      "metadata": {
        "id": "aLbQWQRJMp2S"
      },
      "id": "aLbQWQRJMp2S",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "fb3fbc04",
      "metadata": {
        "id": "fb3fbc04"
      },
      "outputs": [],
      "source": [
        "# # Analsis Grafico -> Python\n",
        "\n",
        "# # Importamos desde R\n",
        "# %R -o resid\n",
        "# %R -o fitted\n",
        "\n",
        "# plt.scatter(x=data.index, y=resid)\n",
        "# plt.xlabel( 'Index')\n",
        "# plt.ylabel('Residuo')\n",
        "# plt.title('Correlacion de Residuos')\n",
        "# plt.axhline(color='grey', linestyle='dashed', alpha=0.5)\n",
        "# plt.show()\n",
        "# # No se observa estructura\n",
        "\n",
        "# # Analisis Analitico -> Python\n",
        "# print('Durbin-Watson:', sm.stats.durbin_watson(resid)) # Sin validacion Estadistica"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformaciones\n",
        "- Cuando los residuos no siguen una distribucion Normal -> Transformamos la y (BoxCox)\n",
        "- Cuando los residuos tienen estructura -> Transformamos/Agregamos X"
      ],
      "metadata": {
        "id": "vevQU54sOiTx"
      },
      "id": "vevQU54sOiTx"
    },
    {
      "cell_type": "code",
      "source": [
        "# # Box Cox Transformation -> R\n",
        "# %%R\n",
        "# data = dataC\n",
        "# library(MASS)\n",
        "\n",
        "# # Modelo existente\n",
        "# model<- lm('dist ~ speed', data=data)\n",
        "\n",
        "# # Buscamos el Lambda  optimo -> Si Lambda  = 0 -> log10(y) | y**Lambda\n",
        "# boxcox(object = model, plotit=TRUE)"
      ],
      "metadata": {
        "id": "yy2EvWj_OuWR"
      },
      "id": "yy2EvWj_OuWR",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # # Generamos el nuevo modelo con las nuevas variables transformadas, y veridicamos su Normalidad\n",
        "# %%R\n",
        "\n",
        "# lmb = 0.5\n",
        "\n",
        "# model_2 <- lm('dist**lmb ~ speed', data=data)\n",
        "# print(shapiro.test(model_2$resid))\n",
        "\n",
        "# # Bandas de Prediccion\n",
        "# predichos <- predict(object=model_2, interval='prediction', level=0.95)\n",
        "# nuevos_datos <- data.frame(predichos, data, data$dist**lmb)\n",
        "# print(head(nuevos_datos))\n",
        "\n",
        "# # # Reverse Transformation\n",
        "# # base = 2\n",
        "# # exp = 3\n",
        "# # print(base**exp)\n",
        "# # print(log(base**exp, base))"
      ],
      "metadata": {
        "id": "ONnQf1q_SnFj"
      },
      "id": "ONnQf1q_SnFj",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Graficamos con las Bandas de Confianza y Prediccion\n",
        "# %R -o nuevos_datos # Exportamos desde R\n",
        "# %R -o lmb\n",
        "\n",
        "# sns.regplot(data=nuevos_datos, x='speed', y='data.dist.lmb')\n",
        "# sns.lineplot(data=nuevos_datos, x='speed', y='lwr', linestyle='--', color='r')\n",
        "# sns.lineplot(data=nuevos_datos, x='speed', y='upr', linestyle='--', color='r')\n",
        "# plt.ylabel('Transformed Distance')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "VaQNrMgoLw9k"
      },
      "id": "VaQNrMgoLw9k",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Boc Cox Transformation -> Python\n",
        "# data = dataC\n",
        "# y = data['dist']\n",
        "\n",
        "# # Calculo Lambda\n",
        "# maxlog = st.boxcox(y)[1]\n",
        "# st.boxcox_normplot(y, -2, 2, plt)\n",
        "# plt.axvline(maxlog, color='red')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "U_d9p-9Bd_N2"
      },
      "id": "U_d9p-9Bd_N2",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deteccion de Valores Outliers e Influyentes"
      ],
      "metadata": {
        "id": "_oOsrltML6nr"
      },
      "id": "_oOsrltML6nr"
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# data <- dataU\n",
        "# # library(car)\n",
        "\n",
        "# # Generamos un modelo base\n",
        "# model <- lm('nassets ~ stfees', data=data)\n",
        "# resid = model$resid\n",
        "# predicted = predict(model)\n",
        "# fitted = model$fitted.values\n",
        "\n",
        "# # Outliers - Bonferroni\n",
        "# qqPlot(resid)\n",
        "# outlierTest(model)\n",
        "# influenceIndexPlot(model, vars='Bonf')\n",
        "\n",
        "# # Influyentes - Leverage\n",
        "# crit_leverage <- 3*mean(hatvalues(model))\n",
        "# leverage <- hatvalues(model) > crit_leverage\n",
        "# leverage_data <- data.frame(cbind(hatvalues(model), crit_leverage, leverage))\n",
        "# print(subset(leverage_data, leverage==1))\n",
        "# # hist(hatvalues(model))\n",
        "\n",
        "# # Influyentes - Cook\n",
        "# # print(cooks.distance(model))\n",
        "# influenceIndexPlot(model, vars='Cook')\n",
        "\n",
        "# # Influyentes - DFFITS\n",
        "# p <- length(model$coef)\n",
        "# n <- NROW(model$resid)\n",
        "# dffits_crit <- 2*sqrt(p/n)\n",
        "# dffits <- dffits(model)\n",
        "# data_dffits <- data.frame(dffits=dffits)\n",
        "\n",
        "# # Influyentes - DFBetas\n",
        "# dfbetas_crit <- 1 # Umbral estandard\n",
        "# dfbetas_data <- dfbetas(model)[,2]>dfbetas_crit\n",
        "# print(which(dfbetas_data))\n",
        "\n",
        "\n",
        "# # Resumen\n",
        "# plot(model)\n",
        "# summary(influence.measures(model=model))\n",
        "# influencePlot(model = model)"
      ],
      "metadata": {
        "id": "1AFS2DQ0e5ow",
        "outputId": "515bb105-af8a-40a5-cb6f-faf834485aa8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "1AFS2DQ0e5ow",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NULL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # DFFITS Grafico -> Python\n",
        "# %R -o data_dffits\n",
        "# %R -o dffits_crit\n",
        "\n",
        "# # Grafico\n",
        "# data_dffits.head()\n",
        "# sns.scatterplot(data=data_dffits, x=data_dffits.index, y='dffits')\n",
        "# plt.axhline(y=dffits_crit, linestyle='--', color='red')\n",
        "# plt.axhline(y=-dffits_crit, linestyle='--', color='red')\n",
        "# plt.xticks(rotation=45)\n",
        "# plt.show()\n",
        "\n",
        "# # Filtro los criticos\n",
        "# dffits_crit_low = -dffits_crit\n",
        "# dffits_crit_up = dffits_crit\n",
        "\n",
        "# display(data_dffits.query('dffits > @dffits_crit_up or dffits < @dffits_crit_low'))"
      ],
      "metadata": {
        "id": "aCwhB3lvRAll"
      },
      "id": "aCwhB3lvRAll",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cuadrados Minimos Ponderados (WLS)\n",
        "- Cuando los residuos son Heterocedasticos\n",
        "- Se compensa la diferencia en los residuos, asignandole diferentes pesos a las observaciones"
      ],
      "metadata": {
        "id": "cXZiAP2wWaEJ"
      },
      "id": "cXZiAP2wWaEJ"
    },
    {
      "cell_type": "code",
      "source": [
        "# # Cuadrados Minimos Ponderados (WLS) en R\n",
        "# %%R\n",
        "\n",
        "# library(lmtest)\n",
        "\n",
        "# # Generamos un modelo base\n",
        "# model_ols <- lm('nassets ~ stfees', data=data)\n",
        "\n",
        "# # Generamos la ponderacion de pesos y modelamos de nuevo\n",
        "# peso1 = 1 / lm(abs(model_ols$resid) ~ model_ols$fitted.values)$fitted.values**2 # Funciona mejor\n",
        "# peso2 = 1 / model_ols$fitted.values**2 # A los valores mas alejados se le reduce el peso\n",
        "\n",
        "# # Modelamos con lo weigths\n",
        "# model_wls1 <- lm('nassets ~ stfees', data=data, weights=peso1)\n",
        "# model_wls2 <- lm('nassets ~ stfees', data=data, weights=peso2)\n",
        "\n",
        "# # Comparamos los modelos\n",
        "# plot(data$stfees, data$nassets, xlab='stfees', ylab='nassets', main='OLS vs WLS')\n",
        "# abline(model_ols, col='black')\n",
        "# abline(model_wls1, col='blue')\n",
        "# abline(model_wls2, col='red')\n"
      ],
      "metadata": {
        "id": "VbT2Q9T9WaNj"
      },
      "id": "VbT2Q9T9WaNj",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelos Robustos\n",
        "- Integran las observaciones atipicas con una menor ponderacion\n",
        "- Cuando Box Cox transformation no  ayudan"
      ],
      "metadata": {
        "id": "2WkEzkAJEytv"
      },
      "id": "2WkEzkAJEytv"
    },
    {
      "cell_type": "code",
      "source": [
        "# %%R\n",
        "\n",
        "# # Huber: Menos peso a residuos grandes. Cuadratica que empalma con lineal\n",
        "# duncan_Huber <- rlm(income ~ education, data=data, k2=1.345)\n",
        "# print(summary(duncan_Huber))\n",
        "\n",
        "# # Rousseeuw LTS: Desconsidera los residuos mas grandes, solo teniendo en cuenta los menores\n",
        "# duncan_LTS <- lqs(income ~ education, data=data, method='lts')\n",
        "# print(duncan_LTS)\n",
        "\n",
        "# # LAD: Suma de valores absolutos\n",
        "# duncan_LAD <- rq(income ~ education, data=data, tau=0.5)\n",
        "# print (duncan_LAD)\n"
      ],
      "metadata": {
        "id": "sxyQxArYFJcE"
      },
      "id": "sxyQxArYFJcE",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regresion Lineal Multiple"
      ],
      "metadata": {
        "id": "qF2YSZbzWNGp"
      },
      "id": "qF2YSZbzWNGp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Seleccion de Variables"
      ],
      "metadata": {
        "id": "rvJSFPJmWWbu"
      },
      "id": "rvJSFPJmWWbu"
    },
    {
      "cell_type": "code",
      "source": [
        "dataS.head()"
      ],
      "metadata": {
        "id": "8JjWCu0QWZXJ",
        "outputId": "2e8898e3-80ab-4ff5-a3f7-a402529be954",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        }
      },
      "id": "8JjWCu0QWZXJ",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Sales  CompPrice  Income  Advertising  Population  Price ShelveLoc  Age  \\\n",
              "0   9.50        138      73           11         276    120       Bad   42   \n",
              "1  11.22        111      48           16         260     83      Good   65   \n",
              "2  10.06        113      35           10         269     80    Medium   59   \n",
              "3   7.40        117     100            4         466     97    Medium   55   \n",
              "4   4.15        141      64            3         340    128       Bad   38   \n",
              "\n",
              "   Education Urban   US  \n",
              "0         17   Yes  Yes  \n",
              "1         10   Yes  Yes  \n",
              "2         12   Yes  Yes  \n",
              "3         14   Yes  Yes  \n",
              "4         13   Yes   No  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-49e51034-c6b6-4096-be4d-b8c47668bda0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sales</th>\n",
              "      <th>CompPrice</th>\n",
              "      <th>Income</th>\n",
              "      <th>Advertising</th>\n",
              "      <th>Population</th>\n",
              "      <th>Price</th>\n",
              "      <th>ShelveLoc</th>\n",
              "      <th>Age</th>\n",
              "      <th>Education</th>\n",
              "      <th>Urban</th>\n",
              "      <th>US</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9.50</td>\n",
              "      <td>138</td>\n",
              "      <td>73</td>\n",
              "      <td>11</td>\n",
              "      <td>276</td>\n",
              "      <td>120</td>\n",
              "      <td>Bad</td>\n",
              "      <td>42</td>\n",
              "      <td>17</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11.22</td>\n",
              "      <td>111</td>\n",
              "      <td>48</td>\n",
              "      <td>16</td>\n",
              "      <td>260</td>\n",
              "      <td>83</td>\n",
              "      <td>Good</td>\n",
              "      <td>65</td>\n",
              "      <td>10</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10.06</td>\n",
              "      <td>113</td>\n",
              "      <td>35</td>\n",
              "      <td>10</td>\n",
              "      <td>269</td>\n",
              "      <td>80</td>\n",
              "      <td>Medium</td>\n",
              "      <td>59</td>\n",
              "      <td>12</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.40</td>\n",
              "      <td>117</td>\n",
              "      <td>100</td>\n",
              "      <td>4</td>\n",
              "      <td>466</td>\n",
              "      <td>97</td>\n",
              "      <td>Medium</td>\n",
              "      <td>55</td>\n",
              "      <td>14</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.15</td>\n",
              "      <td>141</td>\n",
              "      <td>64</td>\n",
              "      <td>3</td>\n",
              "      <td>340</td>\n",
              "      <td>128</td>\n",
              "      <td>Bad</td>\n",
              "      <td>38</td>\n",
              "      <td>13</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49e51034-c6b6-4096-be4d-b8c47668bda0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-49e51034-c6b6-4096-be4d-b8c47668bda0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-49e51034-c6b6-4096-be4d-b8c47668bda0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "data = dataS\n",
        "library(leaps)\n",
        "\n",
        "# consideramos todos los modelos hasta 10 predictoras\n",
        "regfit.todos <- regsubsets(Sales ~., data, nvmax=10)\n",
        "reg.summary <- summary(regfit.todos)\n",
        "# print(reg.summary)\n",
        "\n",
        "# definimos puntos ´optimos para c/ criterio, guardamos su posicion)\n",
        "max_adjr2 = which.max(reg.summary$adjr2)\n",
        "min_cp = which.min(reg.summary$cp)\n",
        "min_bic = which.min(reg.summary$bic)\n",
        "min_aic = which.min(reg.summary$aic)\n",
        "\n",
        "#dataframe para visualizar\n",
        "sal_reg=data.frame(orden=1:10,adjr2=reg.summary$rsq, Cp=reg.summary$cp,Bic=reg.summary$bic)\n",
        "print(sal_reg)\n",
        "\n",
        "# buscaos los coeficientes del modelo con X predictores\n",
        "print(coef(regfit.todos, 7))\n",
        "\n"
      ],
      "metadata": {
        "id": "yCiOgeFrYJyf",
        "outputId": "52622dbc-0119-4822-9d95-49bb1bc89b97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "yCiOgeFrYJyf",
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   orden     adjr2          Cp       Bic\n",
            "1      1 0.2505104 1901.256110 -103.3622\n",
            "2      2 0.4699029 1230.797363 -235.9037\n",
            "3      3 0.6299770  742.155197 -373.7102\n",
            "4      4 0.7124094  491.492304 -468.5296\n",
            "5      5 0.7782355  291.728975 -566.5070\n",
            "6      6 0.8478863   80.242677 -711.3106\n",
            "7      7 0.8719825    8.385679 -774.3036\n",
            "8      8 0.8724943    8.817079 -769.9144\n",
            "9      9 0.8729481    9.426118 -765.3491\n",
            "10    10 0.8733106   10.314876 -760.5007\n",
            "    (Intercept)       CompPrice          Income     Advertising           Price \n",
            "     5.47522623      0.09257147      0.01578497      0.11590340     -0.09531895 \n",
            "  ShelveLocGood ShelveLocMedium             Age \n",
            "     4.83567475      1.95199266     -0.04612752 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "\n",
        "# fijamos una semilla y elegimos un 80% de los datos para entrenar el modelo y el 20% para validarlo\n",
        "set.seed(1123)\n",
        "n <- nrow(data)\n",
        "index <- sample(n, n*0.8, replace = FALSE)\n",
        "train_set = data[index,]\n",
        "test_set = data[-index,]\n",
        "\n",
        "# modelo completo con todas las variables\n",
        "model_full <- lm(Sales ~ ., data=train_set)\n",
        "# modelo s´olo con intercepto\n",
        "model_int <- lm(Sales ~ -., data=test_set)\n",
        "\n",
        "# Modelo Forward\n",
        "# print(n)\n",
        "# print(dim(train_set))\n",
        "# print(dim(test_set))\n",
        "\n",
        "scopeformula <- formula(model_full)\n",
        "fwd_sel <- step(object=model_int, scope=scopeformula, direction='forward')\n",
        "summary(fwd_sel)\n",
        "FwdSelection_AIC = AIC(fwd_sel)"
      ],
      "metadata": {
        "id": "-mPNQEm2d9Nv",
        "outputId": "2dbf9cae-6dca-48c5-e645-baeb01db1b62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "-mPNQEm2d9Nv",
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start:  AIC=165.3\n",
            "Sales ~ -(CompPrice + Income + Advertising + Population + Price + \n",
            "    ShelveLoc + Age + Education + Urban + US)\n",
            "\n",
            "              Df Sum of Sq    RSS    AIC\n",
            "+ Price        1   162.963 453.04 142.72\n",
            "+ ShelveLoc    2   126.601 489.40 150.89\n",
            "+ Advertising  1    95.595 520.40 153.81\n",
            "+ US           1    72.223 543.78 157.32\n",
            "+ Urban        1    45.145 570.85 161.21\n",
            "+ Age          1    25.559 590.44 163.91\n",
            "+ Income       1    22.211 593.79 164.36\n",
            "+ Population   1    16.246 599.75 165.16\n",
            "<none>                     616.00 165.30\n",
            "+ CompPrice    1     3.939 612.06 166.78\n",
            "+ Education    1     0.021 615.98 167.29\n",
            "\n",
            "Step:  AIC=142.72\n",
            "Sales ~ Price\n",
            "\n",
            "              Df Sum of Sq    RSS    AIC\n",
            "+ ShelveLoc    2   145.720 307.32 115.67\n",
            "+ Advertising  1    76.120 376.92 130.00\n",
            "+ CompPrice    1    74.600 378.44 130.32\n",
            "+ US           1    72.416 380.62 130.78\n",
            "+ Urban        1    42.834 410.20 136.77\n",
            "+ Age          1    36.762 416.27 137.94\n",
            "<none>                     453.04 142.72\n",
            "+ Income       1     9.798 443.24 142.97\n",
            "+ Population   1     6.149 446.89 143.62\n",
            "+ Education    1     0.889 452.15 144.56\n",
            "\n",
            "Step:  AIC=115.67\n",
            "Sales ~ Price + ShelveLoc\n",
            "\n",
            "              Df Sum of Sq    RSS     AIC\n",
            "+ CompPrice    1    99.751 207.56  86.274\n",
            "+ US           1    61.579 245.74  99.779\n",
            "+ Advertising  1    60.010 247.31 100.288\n",
            "+ Age          1    48.119 259.20 104.045\n",
            "+ Income       1    24.049 283.27 111.149\n",
            "+ Urban        1    23.261 284.06 111.371\n",
            "<none>                     307.32 115.668\n",
            "+ Population   1     4.386 302.93 116.518\n",
            "+ Education    1     1.881 305.44 117.177\n",
            "\n",
            "Step:  AIC=86.27\n",
            "Sales ~ Price + ShelveLoc + CompPrice\n",
            "\n",
            "              Df Sum of Sq    RSS    AIC\n",
            "+ Advertising  1    61.770 145.79 60.014\n",
            "+ Age          1    49.510 158.06 66.473\n",
            "+ US           1    49.375 158.19 66.542\n",
            "+ Income       1    14.257 193.31 82.581\n",
            "+ Population   1    13.581 193.99 82.860\n",
            "+ Urban        1    11.019 196.55 83.910\n",
            "<none>                     207.56 86.274\n",
            "+ Education    1     2.047 205.52 87.481\n",
            "\n",
            "Step:  AIC=60.01\n",
            "Sales ~ Price + ShelveLoc + CompPrice + Advertising\n",
            "\n",
            "             Df Sum of Sq     RSS    AIC\n",
            "+ Age         1    49.528  96.267 28.808\n",
            "+ Income      1    23.361 122.434 48.044\n",
            "+ US          1     5.899 139.896 58.710\n",
            "+ Urban       1     5.796 139.999 58.769\n",
            "<none>                    145.795 60.014\n",
            "+ Population  1     1.052 144.743 61.435\n",
            "+ Education   1     0.357 145.439 61.818\n",
            "\n",
            "Step:  AIC=28.81\n",
            "Sales ~ Price + ShelveLoc + CompPrice + Advertising + Age\n",
            "\n",
            "             Df Sum of Sq    RSS    AIC\n",
            "+ Income      1   17.5357 78.732 14.722\n",
            "+ US          1    7.8716 88.396 23.984\n",
            "+ Urban       1    4.4952 91.772 26.983\n",
            "<none>                    96.267 28.808\n",
            "+ Education   1    0.1486 96.119 30.685\n",
            "+ Population  1    0.1387 96.129 30.693\n",
            "\n",
            "Step:  AIC=14.72\n",
            "Sales ~ Price + ShelveLoc + CompPrice + Advertising + Age + Income\n",
            "\n",
            "             Df Sum of Sq    RSS    AIC\n",
            "+ US          1    4.6691 74.063 11.831\n",
            "+ Urban       1    2.4690 76.263 14.173\n",
            "<none>                    78.732 14.722\n",
            "+ Education   1    0.4171 78.315 16.297\n",
            "+ Population  1    0.1279 78.604 16.591\n",
            "\n",
            "Step:  AIC=11.83\n",
            "Sales ~ Price + ShelveLoc + CompPrice + Advertising + Age + Income + \n",
            "    US\n",
            "\n",
            "             Df Sum of Sq    RSS    AIC\n",
            "+ Urban       1   1.96481 72.098 11.680\n",
            "<none>                    74.063 11.831\n",
            "+ Education   1   0.38459 73.678 13.414\n",
            "+ Population  1   0.11666 73.946 13.705\n",
            "\n",
            "Step:  AIC=11.68\n",
            "Sales ~ Price + ShelveLoc + CompPrice + Advertising + Age + Income + \n",
            "    US + Urban\n",
            "\n",
            "             Df Sum of Sq    RSS    AIC\n",
            "<none>                    72.098 11.680\n",
            "+ Education   1   0.51855 71.579 13.102\n",
            "+ Population  1   0.08410 72.014 13.586\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}